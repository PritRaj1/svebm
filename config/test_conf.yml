model:
  class_path: src.model.SVEBM
  init_args:
    data_dim: 768
    latent_dim: 64
    
    ebm_model:
      class_path: src.ebm.ebm_model.EBM_fcn
      init_args:
        latent_dim: 64
        num_classes: 2
        hidden_layers: [128, 64]
        activation: relu
        num_latent_samples: 5
        num_gmm_components: 2
        eta: 1.0
        N: 1

    encoder_model:
      class_path: src.variational.encoder_model.EncoderModel
      init_args:
        input_dim: 768
        memory_dim: 64
        latent_dim: 64
        hidden_layers: [128, 64]
        nhead: 4
        dropout: 0.1
        activation: relu
        pad_id: 0

    decoder_model:
      class_path: src.variational.decoder_model.DecoderModel
      init_args:
        vocab_size: 30522
        embed_size: 768
        latent_dim: 64
        memory_dim: 64
        hidden_layers: [64, 128]
        nhead: 4
        dropout: 0.1
        activation: relu
        max_dec_len: 20
        pad_id: 0
        bos_id: 1
        eos_id: 2
        unk_id: 3
        concat_latent: false

    loss_struct:
      class_path: src.criterion.LogProb
      init_args:
        ignore_index: 0
        cls_id: 0
        kl_weight: 0.1
        nll_weight: 1.0

    learning_rate: 0.01
    ebm_learning_rate: 0.001
    gen_type: greedy

    kl_annealer:
      class_path: src.variational.kl_annealing.KLAnnealer
      init_args:
        total_steps: 100
        n_cycle: 1
        ratio_increase: 0.5
        ratio_zero: 0.5
        max_kl_weight: 0.1

data:
  class_path: src.data.data_module.TextDataModule
  init_args:
    dataset_cls: tests.test_model_cli.MockTextDataset
    dataset_kwargs:
      size: 100
      
    batch_size: 8
    num_workers: 2
    val_split: 0.2
    test_split: 0.2
    shuffle: true
    pin_memory: false
    drop_last: false
    seed: 42
    auto_detect_dim: true
    collate_fn:
      class_path: src.collate.create_text_collator
      init_args:
        tokenizer_name: bert-base-uncased
        max_length: 64
        embed_dim: 768
        num_latent_samples: 5
        num_gmm_components: 2

trainer:
  max_epochs: 5
  accelerator: auto
  devices: auto
  precision: 32
  limit_train_batches: 10
  limit_val_batches: 5
  limit_test_batches: 5