model:
  class_path: src.model.SVEBM

  init_args:
    data_dim: null
    latent_dim: 128
    ebm_out_dim: 128
    
    ebm_model:
      class_path: src.ebm.ebm_model.EBM_fcn
      init_args:
        input_dim: ${model.init_args.latent_dim}
        output_dim: ${model.init_args.ebm_out_dim}
        hidden_layers: [256, 128]
        activation: relu

    encoder_model:
      class_path: src.variational.encoder_model.EncoderModel
      init_args:
        input_dim: ${model.init_args.data_dim}
        latent_dim: ${model.init_args.latent_dim}
        hidden_layers: [256, 128]
        nhead: 8
        dropout: 0.1
        activation: relu

    decoder_model:
      class_path: src.variational.decoder_model.DecoderModel
      init_args:
        input_dim: ${model.init_args.ebm_out_dim}
        output_dim: ${model.init_args.data_dim}
        hidden_layers: [128, 256]
        nhead: 8
        dropout: 0.1
        activation: relu
    learning_rate: 0.001

data:
  class_path: src.data.TextDataModule

  init_args:
    dataset_cls: datasets.load_dataset
    dataset_kwargs:
      path: imdb
      split: train
      
    batch_size: 32
    num_workers: 4
    val_split: 0.1
    test_split: 0.1
    shuffle: true
    pin_memory: true
    drop_last: false
    seed: 42
    auto_detect_dim: true
    collate_fn: null

trainer:
  max_epochs: 100
  accelerator: auto
  devices: auto
  precision: 16-mixed 